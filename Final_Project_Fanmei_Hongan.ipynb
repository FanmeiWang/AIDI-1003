{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO758A+7OuIRZ3Nr2lvLxQq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b5e77456b064efb834a38c61adc61c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52289820983c480799c62c80396e97e6",
              "IPY_MODEL_de7c5e6913bd43bc8dc9cb21f972ff16",
              "IPY_MODEL_bae5a098f5c742a7943f2eb7a5e12631"
            ],
            "layout": "IPY_MODEL_e8fca11e0046439a9a603a41e22f9c8e"
          }
        },
        "52289820983c480799c62c80396e97e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6487ecbdfc8478fab5b39da80728dcd",
            "placeholder": "​",
            "style": "IPY_MODEL_7c3471ff42f74b5592ef42826f534e8d",
            "value": "Batches: 100%"
          }
        },
        "de7c5e6913bd43bc8dc9cb21f972ff16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c0f7ade6ae34e5d8a742aaac61fc7d0",
            "max": 655,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_078af88b9561425a9b43b7efc6332eee",
            "value": 655
          }
        },
        "bae5a098f5c742a7943f2eb7a5e12631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db9f80f83a99444fa92e43abed93ccbd",
            "placeholder": "​",
            "style": "IPY_MODEL_26c3c3cbf12f4a0fb3d9fb15f39f1964",
            "value": " 655/655 [02:33&lt;00:00, 50.14it/s]"
          }
        },
        "e8fca11e0046439a9a603a41e22f9c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6487ecbdfc8478fab5b39da80728dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c3471ff42f74b5592ef42826f534e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c0f7ade6ae34e5d8a742aaac61fc7d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "078af88b9561425a9b43b7efc6332eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db9f80f83a99444fa92e43abed93ccbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26c3c3cbf12f4a0fb3d9fb15f39f1964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FanmeiWang/AIDI-1003/blob/main/Final_Project_Fanmei_Hongan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBlCOykHIUhi",
        "outputId": "1a40d7e1-b67f-45e6-cdcc-1634fdb1418c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import html\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "\n",
        "FOLDER_PATH = \"/content/extracted_RS_raw_data\"\n",
        "FILE_PATTERN = \"*.csv\"\n",
        "OUTPUT_CSV = \"/content/cleaned_merged_data.csv\"\n",
        "\n",
        "TITLE_COL = \"title\"\n",
        "SELFTEXT_COL = \"selftext\"\n",
        "CREATED_UTC_COL = \"created_utc\"\n",
        "\n",
        "#2. Text cleaning\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Performs basic text cleaning, including:\n",
        "    - Removing [deleted], [removed], or empty values\n",
        "    - Decoding HTML entities (e.g., &amp; -> &)\n",
        "    - Using unidecode to handle strange unicode characters\n",
        "    - Removing URLs\n",
        "    - Keeping only letters, digits, basic punctuation\n",
        "    - Lowercasing and removing extra whitespace\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text_stripped = text.strip().lower()\n",
        "    if text_stripped in [\"[deleted]\", \"[removed]\", \"\"]:\n",
        "        return \"\"\n",
        "\n",
        "    text = html.unescape(text)\n",
        "    text = unidecode(text)\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s\\.\\,\\!\\?\\']\", \" \", text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "#3. Reading and merging multiple files\n",
        "def read_and_merge(folder_path: str, file_pattern: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Reads all files matching file_pattern from folder_path,\n",
        "    merges them into a single DataFrame, and returns it.\n",
        "    \"\"\"\n",
        "    files = sorted(glob.glob(os.path.join(folder_path, file_pattern)))\n",
        "    if not files:\n",
        "        print(f\"[WARNING] No files found in: {folder_path}/{file_pattern}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    all_dfs = []\n",
        "    for file_path in files:\n",
        "        print(f\"[INFO] Reading: {file_path}\")\n",
        "        if file_path.endswith(\".csv\"):\n",
        "            df = pd.read_csv(file_path, encoding=\"utf-8\", keep_default_na=False)\n",
        "        else:\n",
        "            df = pd.read_excel(file_path, engine=\"openpyxl\", keep_default_na=False)\n",
        "        all_dfs.append(df)\n",
        "\n",
        "    if not all_dfs:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    merged_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    print(f\"[INFO] Successfully merged {len(files)} file(s). Total rows: {len(merged_df)}\")\n",
        "    return merged_df\n",
        "\n",
        "#4. Main process: merging, cleaning, adding \"month\" column\n",
        "df_merged = read_and_merge(FOLDER_PATH, FILE_PATTERN)\n",
        "\n",
        "if df_merged.empty:\n",
        "    print(\"[ERROR] No data to process. Exiting.\")\n",
        "else:\n",
        "\n",
        "    if CREATED_UTC_COL in df_merged.columns:\n",
        "        df_merged[\"created_dt\"] = pd.to_datetime(df_merged[CREATED_UTC_COL], unit=\"s\", errors=\"coerce\")\n",
        "        df_merged[\"month\"] = df_merged[\"created_dt\"].dt.strftime(\"%Y-%m\")\n",
        "    else:\n",
        "        print(f\"[WARNING] Column '{CREATED_UTC_COL}' not found. Unable to create 'month'.\")\n",
        "        df_merged[\"created_dt\"] = None\n",
        "        df_merged[\"month\"] = None\n",
        "\n",
        "    df_merged[\"combined_text\"] = (\n",
        "        df_merged.get(TITLE_COL, \"\").fillna(\"\") + \" \" + df_merged.get(SELFTEXT_COL, \"\").fillna(\"\")\n",
        "    )\n",
        "\n",
        "    df_merged[\"clean_text\"] = df_merged[\"combined_text\"].apply(clean_text)\n",
        "\n",
        "    before_drop = len(df_merged)\n",
        "    df_merged = df_merged[df_merged[\"clean_text\"].str.strip() != \"\"]\n",
        "    after_drop = len(df_merged)\n",
        "    print(f\"[INFO] Dropped {before_drop - after_drop} empty rows. Remaining rows: {after_drop}\")\n",
        "\n",
        "    output_path = os.path.join(FOLDER_PATH, OUTPUT_CSV)\n",
        "    df_merged.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
        "    print(f\"[DONE] Cleaned data saved to: {output_path}\")\n",
        "\n",
        "    print(\"[INFO] DataFrame columns:\", df_merged.columns.tolist())\n",
        "    print(\"[INFO] Head of the DataFrame:\")\n",
        "    print(df_merged.head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMNLbgcUTJhk",
        "outputId": "1e2e5b59-0ea8-4935-dfd9-301455257e42"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2022-12_filtered.csv\n",
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2023-01_filtered.csv\n",
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2023-02_filtered.csv\n",
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2023-03_filtered.csv\n",
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2023-04_filtered.csv\n",
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2023-05_filtered.csv\n",
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2023-06_filtered.csv\n",
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2023-07_filtered.csv\n",
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2023-08_filtered.csv\n",
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2023-09_filtered.csv\n",
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2023-10_filtered.csv\n",
            "[INFO] Reading: /content/extracted_RS_raw_data/extracted_RS_2023-11_filtered.csv\n",
            "[INFO] Successfully merged 12 file(s). Total rows: 20936\n",
            "[INFO] Dropped 0 empty rows. Remaining rows: 20936\n",
            "[DONE] Cleaned data saved to: /content/cleaned_merged_data.csv\n",
            "[INFO] DataFrame columns: ['subreddit', 'title', 'selftext', 'created_utc', 'created_dt', 'month', 'combined_text', 'clean_text']\n",
            "[INFO] Head of the DataFrame:\n",
            "           subreddit                                              title  \\\n",
            "0  ImmigrationCanada  Received the nomination letter in EE but not r...   \n",
            "1  ImmigrationCanada  PGWP approved, Can I apply for OHIP immediatel...   \n",
            "2  ImmigrationCanada                 OHIP on Interim work authorization   \n",
            "\n",
            "                                            selftext   created_utc  \\\n",
            "0                                          [deleted]  1.669855e+09   \n",
            "1  I have the approval letter, just waiting for t...  1.669855e+09   \n",
            "2                                          [removed]  1.669857e+09   \n",
            "\n",
            "           created_dt    month  \\\n",
            "0 2022-12-01 00:39:40  2022-12   \n",
            "1 2022-12-01 00:42:03  2022-12   \n",
            "2 2022-12-01 01:17:41  2022-12   \n",
            "\n",
            "                                       combined_text  \\\n",
            "0  Received the nomination letter in EE but not r...   \n",
            "1  PGWP approved, Can I apply for OHIP immediatel...   \n",
            "2       OHIP on Interim work authorization [removed]   \n",
            "\n",
            "                                          clean_text  \n",
            "0  received the nomination letter in ee but not r...  \n",
            "1  pgwp approved, can i apply for ohip immediatel...  \n",
            "2         ohip on interim work authorization removed  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertopic hdbscan umap-learn sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_ReSfvDZsFW",
        "outputId": "ad14c401-d7d7-4f0d-9cf1-826a99541d0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bertopic\n",
            "  Downloading bertopic-0.17.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: hdbscan in /usr/local/lib/python3.11/dist-packages (0.8.40)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (0.5.7)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan) (1.4.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (9.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading bertopic-0.17.0-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bertopic\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bertopic-0.17.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# (1) Imports\n",
        "# ============================================\n",
        "import pandas as pd\n",
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ============================================\n",
        "# (2) Load cleaned data\n",
        "# ============================================\n",
        "DATA_CSV = \"/content/cleaned_merged_data.csv\"  # change this path if needed\n",
        "df = pd.read_csv(DATA_CSV, encoding=\"utf-8\")\n",
        "\n",
        "print(\"[INFO] Columns:\", df.columns.tolist())\n",
        "print(df.head(3))\n",
        "\n",
        "# Filter out empty rows\n",
        "df = df[df[\"clean_text\"].str.strip() != \"\"].reset_index(drop=True)\n",
        "print(\"[INFO] Number of documents after filtering:\", len(df))\n",
        "\n",
        "# ============================================\n",
        "# (3) Prepare documents for BERTopic\n",
        "# ============================================\n",
        "docs = df[\"clean_text\"].tolist()\n",
        "\n",
        "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
        "topic_model = BERTopic(\n",
        "    embedding_model=embedding_model,\n",
        "    verbose=True,\n",
        "    calculate_probabilities=True\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "topics, probs = topic_model.fit_transform(docs)\n",
        "df[\"topic_id\"] = topics\n",
        "\n",
        "# ============================================\n",
        "# (4) Basic topic info\n",
        "# ============================================\n",
        "topic_info = topic_model.get_topic_info()\n",
        "print(\"[INFO] Topic info (head):\")\n",
        "print(topic_info.head(10))\n",
        "\n",
        "# ============================================\n",
        "# (5) Exclude outliers where topic_id = -1\n",
        "# ============================================\n",
        "df_no_outliers = df[df[\"topic_id\"] != -1].copy()\n",
        "print(\"[INFO] Removed outliers with topic_id = -1. Remaining docs:\", len(df_no_outliers))\n",
        "\n",
        "# ============================================\n",
        "# (6) Month-topic distribution\n",
        "# ============================================\n",
        "if \"month\" in df_no_outliers.columns:\n",
        "    # Group by month and topic_id\n",
        "    month_topic_counts = (\n",
        "        df_no_outliers.groupby([\"month\", \"topic_id\"]).size()\n",
        "          .reset_index(name=\"count\")\n",
        "          .sort_values([\"month\", \"count\"], ascending=[True, False])\n",
        "    )\n",
        "    print(\"[INFO] Month-topic distribution (top rows):\")\n",
        "    print(month_topic_counts.head(10))\n",
        "else:\n",
        "    print(\"[WARNING] No 'month' column found in df_no_outliers; skipping month-based stats.\")\n",
        "\n",
        "# ============================================\n",
        "# (7) Pivot to compare monthly differences\n",
        "# ============================================\n",
        "if \"month\" in df_no_outliers.columns:\n",
        "    # Pivot\n",
        "    pivot_data = month_topic_counts.pivot(\n",
        "        index=\"month\", columns=\"topic_id\", values=\"count\"\n",
        "    ).fillna(0)\n",
        "\n",
        "    # Sort by chronological order if month is like YYYY-MM\n",
        "    pivot_data = pivot_data.sort_index()\n",
        "    print(\"[INFO] Pivoted data shape:\", pivot_data.shape)\n",
        "    print(pivot_data.head())\n",
        "\n",
        "    # Compute month-to-month difference\n",
        "    diff_data = pivot_data.diff().fillna(0)\n",
        "\n",
        "    # Flatten back to long format\n",
        "    diff_long = diff_data.reset_index().melt(\n",
        "        id_vars=[\"month\"], var_name=\"topic_id\", value_name=\"diff_value\"\n",
        "    )\n",
        "    diff_long = diff_long.sort_values(\"diff_value\", ascending=False)\n",
        "\n",
        "    print(\"[INFO] Largest monthly jumps (head 10):\")\n",
        "    print(diff_long.head(10))\n",
        "\n",
        "    # Pick the topic-month with the biggest jump\n",
        "    if len(diff_long) > 0:\n",
        "        most_changed = diff_long.iloc[0]\n",
        "        max_topic = most_changed[\"topic_id\"]\n",
        "        max_month = most_changed[\"month\"]\n",
        "        max_diff = most_changed[\"diff_value\"]\n",
        "\n",
        "        print(f\"[INFO] Topic {max_topic} in month {max_month} had the largest jump of {max_diff} docs.\")\n",
        "\n",
        "        # Extract the docs for that topic-month\n",
        "        df_chosen = df_no_outliers[\n",
        "            (df_no_outliers[\"topic_id\"] == max_topic) &\n",
        "            (df_no_outliers[\"month\"] == max_month)\n",
        "        ].copy()\n",
        "        print(\"[INFO] Example docs for that topic & month:\")\n",
        "        print(df_chosen[\"clean_text\"].head(5))\n",
        "\n",
        "else:\n",
        "    print(\"[WARNING] Skipping pivot/diff because no 'month' column found.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4b5e77456b064efb834a38c61adc61c6",
            "52289820983c480799c62c80396e97e6",
            "de7c5e6913bd43bc8dc9cb21f972ff16",
            "bae5a098f5c742a7943f2eb7a5e12631",
            "e8fca11e0046439a9a603a41e22f9c8e",
            "f6487ecbdfc8478fab5b39da80728dcd",
            "7c3471ff42f74b5592ef42826f534e8d",
            "8c0f7ade6ae34e5d8a742aaac61fc7d0",
            "078af88b9561425a9b43b7efc6332eee",
            "db9f80f83a99444fa92e43abed93ccbd",
            "26c3c3cbf12f4a0fb3d9fb15f39f1964"
          ]
        },
        "id": "yO0p7XECasR8",
        "outputId": "8e5b5d5d-9c54-43fe-e82c-f485a28ce726"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Columns: ['subreddit', 'title', 'selftext', 'created_utc', 'created_dt', 'month', 'combined_text', 'clean_text']\n",
            "           subreddit                                              title  \\\n",
            "0  ImmigrationCanada  Received the nomination letter in EE but not r...   \n",
            "1  ImmigrationCanada  PGWP approved, Can I apply for OHIP immediatel...   \n",
            "2  ImmigrationCanada                 OHIP on Interim work authorization   \n",
            "\n",
            "                                            selftext   created_utc  \\\n",
            "0                                          [deleted]  1.669855e+09   \n",
            "1  I have the approval letter, just waiting for t...  1.669855e+09   \n",
            "2                                          [removed]  1.669857e+09   \n",
            "\n",
            "            created_dt    month  \\\n",
            "0  2022-12-01 00:39:40  2022-12   \n",
            "1  2022-12-01 00:42:03  2022-12   \n",
            "2  2022-12-01 01:17:41  2022-12   \n",
            "\n",
            "                                       combined_text  \\\n",
            "0  Received the nomination letter in EE but not r...   \n",
            "1  PGWP approved, Can I apply for OHIP immediatel...   \n",
            "2       OHIP on Interim work authorization [removed]   \n",
            "\n",
            "                                          clean_text  \n",
            "0  received the nomination letter in ee but not r...  \n",
            "1  pgwp approved, can i apply for ohip immediatel...  \n",
            "2         ohip on interim work authorization removed  \n",
            "[INFO] Number of documents after filtering: 20936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-12 15:06:38,432 - BERTopic - Embedding - Transforming documents to embeddings.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/655 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b5e77456b064efb834a38c61adc61c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-12 15:09:13,715 - BERTopic - Embedding - Completed ✓\n",
            "2025-04-12 15:09:13,717 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
            "2025-04-12 15:09:32,699 - BERTopic - Dimensionality - Completed ✓\n",
            "2025-04-12 15:09:32,701 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
            "2025-04-12 15:10:33,686 - BERTopic - Cluster - Completed ✓\n",
            "2025-04-12 15:10:33,696 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
            "2025-04-12 15:10:34,849 - BERTopic - Representation - Completed ✓\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Topic info (head):\n",
            "   Topic  Count                                    Name  \\\n",
            "0     -1   7807                        -1_to_the_and_my   \n",
            "1      0    772       0_we_married_sponsorship_together   \n",
            "2      1    695                   1_card_pr_travel_back   \n",
            "3      2    502       2_experience_hours_company_worked   \n",
            "4      3    256               3_lmia_offer_employer_job   \n",
            "5      4    246           4_removed_deleted_help_please   \n",
            "6      5    239              5_medical_exam_ime_upfront   \n",
            "7      6    231          6_immigrate_move_canada_moving   \n",
            "8      7    196  7_biometrics_biometric_fee_appointment   \n",
            "9      8    177              8_wes_eca_degree_education   \n",
            "\n",
            "                                      Representation  \\\n",
            "0  [to, the, and, my, for, in, permit, is, of, work]   \n",
            "1  [we, married, sponsorship, together, her, comm...   \n",
            "2  [card, pr, travel, back, ecopr, prtd, citizens...   \n",
            "3  [experience, hours, company, worked, count, re...   \n",
            "4  [lmia, offer, employer, job, exempt, points, 5...   \n",
            "5  [removed, deleted, help, please, advice, urgen...   \n",
            "6  [medical, exam, ime, upfront, examination, don...   \n",
            "7  [immigrate, move, canada, moving, looking, wan...   \n",
            "8  [biometrics, biometric, fee, appointment, inst...   \n",
            "9  [wes, eca, degree, education, diploma, degrees...   \n",
            "\n",
            "                                 Representative_Docs  \n",
            "0  [struggling to choose between fsw or cec progr...  \n",
            "1  [best way for sponsorship hello all, i would w...  \n",
            "2  [just received approval for my pr application ...  \n",
            "3  [fsw express entry are contract employment fte...  \n",
            "4  [is a job offer valid 50 points if the lmia ex...  \n",
            "5            [help removed, help ? removed, removed]  \n",
            "6  [medical exam for pgwp do i need a medical exa...  \n",
            "7  [from mexico to canada hey! 23 y o mexican fir...  \n",
            "8  [when do i submit my biometrics? study permit ...  \n",
            "9  [wes for us masters degree hi i am trying to a...  \n",
            "[INFO] Removed outliers with topic_id = -1. Remaining docs: 13129\n",
            "[INFO] Month-topic distribution (top rows):\n",
            "      month  topic_id  count\n",
            "1   2022-12         1     45\n",
            "0   2022-12         0     44\n",
            "2   2022-12         2     26\n",
            "4   2022-12         4     21\n",
            "5   2022-12         5     20\n",
            "11  2022-12        11     19\n",
            "9   2022-12         9     15\n",
            "22  2022-12        22     15\n",
            "6   2022-12         6     14\n",
            "12  2022-12        12     14\n",
            "[INFO] Pivoted data shape: (12, 270)\n",
            "topic_id   0     1     2     3     4     5     6     7     8     9    ...  \\\n",
            "month                                                                 ...   \n",
            "2022-12   44.0  45.0  26.0  12.0  21.0  20.0  14.0   3.0   7.0  15.0  ...   \n",
            "2023-01   72.0  59.0  47.0  15.0  21.0  18.0  39.0   5.0  14.0  17.0  ...   \n",
            "2023-02   60.0  50.0  29.0  15.0  25.0  11.0  10.0  11.0   7.0  11.0  ...   \n",
            "2023-03    6.0  10.0   7.0   7.0   2.0   2.0   3.0   0.0   1.0   1.0  ...   \n",
            "2023-04   60.0  53.0  43.0  14.0  21.0  16.0  20.0  22.0  20.0  35.0  ...   \n",
            "\n",
            "topic_id  260  261  262  263  264  265  266  267  268  269  \n",
            "month                                                       \n",
            "2022-12   0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
            "2023-01   0.0  1.0  0.0  1.0  1.0  1.0  0.0  3.0  0.0  0.0  \n",
            "2023-02   1.0  0.0  1.0  0.0  0.0  2.0  2.0  1.0  0.0  1.0  \n",
            "2023-03   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2023-04   1.0  0.0  0.0  0.0  0.0  1.0  0.0  2.0  1.0  2.0  \n",
            "\n",
            "[5 rows x 270 columns]\n",
            "[INFO] Largest monthly jumps (head 10):\n",
            "        month topic_id  diff_value\n",
            "4     2023-04        0        54.0\n",
            "16    2023-04        1        43.0\n",
            "28    2023-04        2        36.0\n",
            "112   2023-04        9        34.0\n",
            "1     2023-01        0        28.0\n",
            "1252  2023-04      104        27.0\n",
            "73    2023-01        6        25.0\n",
            "352   2023-04       29        25.0\n",
            "31    2023-07        2        23.0\n",
            "196   2023-04       16        23.0\n",
            "[INFO] Topic 0 in month 2023-04 had the largest jump of 54.0 docs.\n",
            "[INFO] Example docs for that topic & month:\n",
            "5046    best options for migrating from australia to c...\n",
            "5089    need to prove cohabitation since submitting? p...\n",
            "5093    sponsor a common law partner long distance rel...\n",
            "5122    question about common law and working in canad...\n",
            "5135    canada or ph wedding? does canada has less wed...\n",
            "Name: clean_text, dtype: object\n"
          ]
        }
      ]
    }
  ]
}